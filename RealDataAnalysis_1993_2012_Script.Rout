
R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin13.4.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list=ls())
> 
> ############################################################################
> ############################################################################
> ############################################################################
> ###
> ### Real Data Analysis
> ###
> ############################################################################
> ############################################################################
> ############################################################################
> 
> ###
> ### Packages and dependencies
> ###
> 
> required.packages=c("coda",
+                     "fBasics",
+                     "fields",
+                     "ggmap",
+                     "ggplot2",
+                     "gridExtra",
+                     "gstat",
+                     "inline",
+                     "maptools",
+                     "raster",
+                     "rasterVis",
+                     "RCurl",
+                     "RColorBrewer",
+                     "RcppArmadillo",
+                     "rgdal",
+                     "rgeos")
> ## install.packages(required.packages)
> lapply(required.packages,library,character.only=TRUE)
Loading required package: timeDate
Loading required package: timeSeries


Rmetrics Package fBasics
Analysing Markets and calculating Basic Statistics
Copyright (C) 2005-2014 Rmetrics Association Zurich
Educational Software for Financial Engineering and Computational Science
Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
https://www.rmetrics.org --- Mail to: info@rmetrics.org
Loading required package: spam
Loading required package: dotCall64
Loading required package: grid
Spam version 2.1-2 (2017-12-21) is loaded.
Type 'help( Spam)' or 'demo( spam)' for a short introduction 
and overview of this package.
Help for individual functions is also obtained by adding the
suffix '.spam' to the function name, e.g. 'help( chol.spam)'.

Attaching package: ‘spam’

The following objects are masked from ‘package:base’:

    backsolve, forwardsolve

Loading required package: maps
Loading required package: ggplot2
Google Maps API Terms of Service: http://developers.google.com/maps/terms.
Please cite ggmap if you use it: see citation("ggmap") for details.
Loading required package: sp
Checking rgeos availability: TRUE
Loading required package: lattice
Loading required package: latticeExtra
Loading required package: RColorBrewer

Attaching package: ‘latticeExtra’

The following object is masked from ‘package:ggplot2’:

    layer

Loading required package: bitops
rgdal: version: 1.2-5, (SVN revision 648)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 2.1.2, released 2016/10/24
 Path to GDAL shared files: /Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgdal/gdal
 Loaded PROJ.4 runtime: Rel. 4.9.1, 04 March 2015, [PJ_VERSION: 491]
 Path to PROJ.4 shared files: /Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgdal/proj
 Linking to sp version: 1.2-4 

Attaching package: ‘rgdal’

The following object is masked from ‘package:fBasics’:

    getDescription

rgeos version: 0.3-26, (SVN revision 560)
 GEOS runtime version: 3.4.2-CAPI-1.8.2 r3921 
 Linking to sp version: 1.2-5 
 Polygon checking: TRUE 

[[1]]
[1] "coda"      "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[7] "methods"   "base"     

[[2]]
 [1] "fBasics"    "timeSeries" "timeDate"   "coda"       "stats"     
 [6] "graphics"   "grDevices"  "utils"      "datasets"   "methods"   
[11] "base"      

[[3]]
 [1] "fields"     "maps"       "spam"       "grid"       "dotCall64" 
 [6] "fBasics"    "timeSeries" "timeDate"   "coda"       "stats"     
[11] "graphics"   "grDevices"  "utils"      "datasets"   "methods"   
[16] "base"      

[[4]]
 [1] "ggmap"      "ggplot2"    "fields"     "maps"       "spam"      
 [6] "grid"       "dotCall64"  "fBasics"    "timeSeries" "timeDate"  
[11] "coda"       "stats"      "graphics"   "grDevices"  "utils"     
[16] "datasets"   "methods"    "base"      

[[5]]
 [1] "ggmap"      "ggplot2"    "fields"     "maps"       "spam"      
 [6] "grid"       "dotCall64"  "fBasics"    "timeSeries" "timeDate"  
[11] "coda"       "stats"      "graphics"   "grDevices"  "utils"     
[16] "datasets"   "methods"    "base"      

[[6]]
 [1] "gridExtra"  "ggmap"      "ggplot2"    "fields"     "maps"      
 [6] "spam"       "grid"       "dotCall64"  "fBasics"    "timeSeries"
[11] "timeDate"   "coda"       "stats"      "graphics"   "grDevices" 
[16] "utils"      "datasets"   "methods"    "base"      

[[7]]
 [1] "gstat"      "gridExtra"  "ggmap"      "ggplot2"    "fields"    
 [6] "maps"       "spam"       "grid"       "dotCall64"  "fBasics"   
[11] "timeSeries" "timeDate"   "coda"       "stats"      "graphics"  
[16] "grDevices"  "utils"      "datasets"   "methods"    "base"      

[[8]]
 [1] "inline"     "gstat"      "gridExtra"  "ggmap"      "ggplot2"   
 [6] "fields"     "maps"       "spam"       "grid"       "dotCall64" 
[11] "fBasics"    "timeSeries" "timeDate"   "coda"       "stats"     
[16] "graphics"   "grDevices"  "utils"      "datasets"   "methods"   
[21] "base"      

[[9]]
 [1] "maptools"   "sp"         "inline"     "gstat"      "gridExtra" 
 [6] "ggmap"      "ggplot2"    "fields"     "maps"       "spam"      
[11] "grid"       "dotCall64"  "fBasics"    "timeSeries" "timeDate"  
[16] "coda"       "stats"      "graphics"   "grDevices"  "utils"     
[21] "datasets"   "methods"    "base"      

[[10]]
 [1] "raster"     "maptools"   "sp"         "inline"     "gstat"     
 [6] "gridExtra"  "ggmap"      "ggplot2"    "fields"     "maps"      
[11] "spam"       "grid"       "dotCall64"  "fBasics"    "timeSeries"
[16] "timeDate"   "coda"       "stats"      "graphics"   "grDevices" 
[21] "utils"      "datasets"   "methods"    "base"      

[[11]]
 [1] "rasterVis"    "latticeExtra" "RColorBrewer" "lattice"      "raster"      
 [6] "maptools"     "sp"           "inline"       "gstat"        "gridExtra"   
[11] "ggmap"        "ggplot2"      "fields"       "maps"         "spam"        
[16] "grid"         "dotCall64"    "fBasics"      "timeSeries"   "timeDate"    
[21] "coda"         "stats"        "graphics"     "grDevices"    "utils"       
[26] "datasets"     "methods"      "base"        

[[12]]
 [1] "RCurl"        "bitops"       "rasterVis"    "latticeExtra" "RColorBrewer"
 [6] "lattice"      "raster"       "maptools"     "sp"           "inline"      
[11] "gstat"        "gridExtra"    "ggmap"        "ggplot2"      "fields"      
[16] "maps"         "spam"         "grid"         "dotCall64"    "fBasics"     
[21] "timeSeries"   "timeDate"     "coda"         "stats"        "graphics"    
[26] "grDevices"    "utils"        "datasets"     "methods"      "base"        

[[13]]
 [1] "RCurl"        "bitops"       "rasterVis"    "latticeExtra" "RColorBrewer"
 [6] "lattice"      "raster"       "maptools"     "sp"           "inline"      
[11] "gstat"        "gridExtra"    "ggmap"        "ggplot2"      "fields"      
[16] "maps"         "spam"         "grid"         "dotCall64"    "fBasics"     
[21] "timeSeries"   "timeDate"     "coda"         "stats"        "graphics"    
[26] "grDevices"    "utils"        "datasets"     "methods"      "base"        

[[14]]
 [1] "RcppArmadillo" "RCurl"         "bitops"        "rasterVis"    
 [5] "latticeExtra"  "RColorBrewer"  "lattice"       "raster"       
 [9] "maptools"      "sp"            "inline"        "gstat"        
[13] "gridExtra"     "ggmap"         "ggplot2"       "fields"       
[17] "maps"          "spam"          "grid"          "dotCall64"    
[21] "fBasics"       "timeSeries"    "timeDate"      "coda"         
[25] "stats"         "graphics"      "grDevices"     "utils"        
[29] "datasets"      "methods"       "base"         

[[15]]
 [1] "rgdal"         "RcppArmadillo" "RCurl"         "bitops"       
 [5] "rasterVis"     "latticeExtra"  "RColorBrewer"  "lattice"      
 [9] "raster"        "maptools"      "sp"            "inline"       
[13] "gstat"         "gridExtra"     "ggmap"         "ggplot2"      
[17] "fields"        "maps"          "spam"          "grid"         
[21] "dotCall64"     "fBasics"       "timeSeries"    "timeDate"     
[25] "coda"          "stats"         "graphics"      "grDevices"    
[29] "utils"         "datasets"      "methods"       "base"         

[[16]]
 [1] "rgeos"         "rgdal"         "RcppArmadillo" "RCurl"        
 [5] "bitops"        "rasterVis"     "latticeExtra"  "RColorBrewer" 
 [9] "lattice"       "raster"        "maptools"      "sp"           
[13] "inline"        "gstat"         "gridExtra"     "ggmap"        
[17] "ggplot2"       "fields"        "maps"          "spam"         
[21] "grid"          "dotCall64"     "fBasics"       "timeSeries"   
[25] "timeDate"      "coda"          "stats"         "graphics"     
[29] "grDevices"     "utils"         "datasets"      "methods"      
[33] "base"         

Warning message:
In as.POSIXlt.POSIXct(Sys.time()) :
  unknown timezone 'zone/tz/2018c.1.0/zoneinfo/America/Denver'
> 
> ## C++ sampler for projection
> code <- '
+     arma::mat Hmat = Rcpp::as<arma::mat>(H);
+     arma::mat c0mat = Rcpp::as<arma::mat>(c0);
+     int steps = Rcpp::as<int>(timesteps);
+     int n = steps;
+     int k = Hmat.n_rows;
+     arma::mat call(k,n);
+     call.col(0)=Hmat*c0mat;
+     for(int i = 1; i < n; ++i){
+       call.col(i)=Hmat*call.col(i-1);
+     }
+     return Rcpp::wrap(call);
+   '
> calcc = cxxfunction(signature(H="numeric",c0="numeric",timesteps="numeric"),
+                     body=code, plugin="RcppArmadillo")
> 
> ## Neighborhood matrix calculator
> neighborhood=function(raster, boundary){
+     nn=matrix(,length(raster[]),4)
+     for(i in 1:dim(nn)[1]){
+         if(extract(boundary,i)==1){
+             loc=adjacent(raster,i)[,2]
+             ln=loc[which((loc+1)==i)]
+             rn=loc[which((loc-1)==i)]
+             bn=loc[which((loc-dim(raster)[2])==i)]
+             tn=loc[which((loc+dim(raster)[2])==i)]
+             nn[i,1]=if(length(ln)>0 & extract(boundary,ln)>0){ln}else{0}
+             nn[i,2]=if(length(rn)>0 & extract(boundary,rn)>0){rn}else{0}
+             nn[i,3]=if(length(bn)>0 & extract(boundary,bn)>0){bn}else{0}
+             nn[i,4]=if(length(tn)>0 & extract(boundary,tn)>0){tn}else{0}
+         }else{nn[i,]=0}
+     }
+     nn
+ }
> 
> ## Propagator matrix for plain diffusion PDE
> propagator.plainZF=function(NN,delta,gamma,dx,dy,dt){
+     H <- matrix(0,dim(NN)[1],dim(NN)[1])
+     for(i in 1:dim(H)[1]){
+         if(length(which(NN[i,]>0))>0){
+             ind.tmp=ifelse(NN[i,]>0,1,0)
+             H[i,i]=1-2*delta[i]*
+                 (dt/dx^2+dt/dy^2)+dt*gamma[i]+
+                 dt/dx^2*delta[i]*(1-ind.tmp[1])+
+                           dt/dx^2*delta[i]*(1-ind.tmp[2])+
+                                     dt/dy^2*delta[i]*(1-ind.tmp[3])+
+                                               dt/dy^2*delta[i]*
+                                                         (1-ind.tmp[4])
+             H[i,NN[i,1]]=dt/dx^2*delta[i]*ind.tmp[1]
+             H[i,NN[i,2]]=dt/dx^2*delta[i]*ind.tmp[2]
+             H[i,NN[i,3]]=dt/dy^2*delta[i]*ind.tmp[3]
+             H[i,NN[i,4]]=dt/dy^2*delta[i]*ind.tmp[4]
+         }else{H[i,i]=0}
+     }
+     H
+ }
> 
> #############################################
> ### Load Bathymetry Data
> #############################################
> 
> ## This file is available on GitHub
> load("~/Dropbox/Post-Doc/RFiles/lutris/data/bath.raster.RData")
> 
> ###
> ### Study area extent
> ###
> 
> xmin=404000
> xmax=460000
> ymin=6460000
> ymax=6528000
> 
> ###
> ### Initial condition
> ###
> 
> d=c(442000,6465000)
> 
> ###
> ### Discretization values
> ###
> 
> dt=1/200
> time.steps=1/dt*length(1993:2012)
> keep=seq(1,time.steps,time.steps/length(1993:2012))
> 
> ###
> ### Homogenization value
> ###
> 
> us.fact=10
> 
> ###
> ### Bathymetry data
> ###
> 
> bath.tmp=crop(bath.raster,extent(xmin,xmax,ymin,ymax))
> Bath.r=aggregate(bath.tmp,c(16,16),na.rm=TRUE)
> Bath.r[94,92]=NA  # add boulder island
> x=dim(Bath.r)[2]
> y=dim(Bath.r)[1]
> q=x*y
> 
> ###
> ### Aggregate values
> ###
> 
> bath=crop(Bath.r,extent(xmin,xmax,ymin,ymax))
> 
> ###
> ### Load Glacier Bay Sea Otter Data
> ###
> 
> data=read.csv("~/Dropbox/Post-Doc/OriginalDataFiles/GLBA_noDots.csv")
> dataDistr=read.csv(paste("~/Dropbox/Post-Doc/OriginalDataFiles/",
+                          "DistribSurveysC.csv",
+                          sep=""))
> ind.pred.tmp=1:dim(dataDistr)[1]
> ind.pred=ind.pred.tmp[dataDistr$year==2004|dataDistr$year==2006]
> dataDistr=dataDistr[-ind.pred,]
> ind=1993:2012
> 
> ###
> ### Convert Data to Raster
> ###
> 
> cell=raster(,nrows=y,ncols=x,xmn=xmin,xmx=xmax,
+             ymn=ymin,ymx=ymax,crs=NA)
> CISU=N.r=ISUind.r=Y.r=Counts=Boundary=BoundaryDist=DistCov=DepthCov=gamma=delta=lambda0=SurvR=SimulatedDataR=cell
> c0=raster(,nrows=y/us.fact,ncols=x/us.fact,
+           xmn=xmin,xmx=xmax,ymn=ymin,ymx=ymax,
+           crs=NA)
> data.r=raster(,nrows=y,ncols=x,xmn=xmin,
+               xmx=xmax,ymn=ymin,ymx=ymax,crs=0)
> data1.sub=subset(data,year=="1993")
> data1.sub=data1.sub[!is.na(data1.sub$GROUP_X),]
> data2.sub=subset(dataDistr,year=="1993")
> x_loc=c(data1.sub$Group_X,data2.sub$POINT_X)
> y_loc=c(data1.sub$Group_Y,data2.sub$POINT_Y)
> Counts.tmp=c(data1.sub$animals,data2.sub$animals)
> Counts.sub=rasterize(x=cbind(x_loc,y_loc),y=data.r,
+                      field=Counts.tmp,fun="max",na.rm=TRUE,background=0)
> Counts[]=Counts.sub[]
> Counts=stack(mget(rep("Counts",20)))
> years=1994:2012
> ind=2
> for(t in years){
+     data1.sub=subset(data,year==t)
+     data1.sub=data1.sub[!is.na(data1.sub$GROUP_X),]
+     data2.sub=subset(dataDistr,year==t)
+     x_loc=c(data1.sub$GROUP_X,data2.sub$POINT_X)
+     y_loc=c(data1.sub$GROUP_Y,data2.sub$POINT_Y)
+     Counts.tmp=c(data1.sub$animals,data2.sub$animals)
+     if(length(x_loc)>0){
+         Counts.sub=rasterize(x=cbind(x_loc,y_loc),
+                              y=data.r,field=Counts.tmp,fun="max",na.rm=TRUE,
+                              background=0)
+         Counts[[ind]][]=Counts.sub[]
+     }else{
+         Counts[[ind]][]=rep(NA,q)
+     }
+     ind=ind+1
+ }
> ## plot(Counts)
> 
> ###################################################################
> ### Transects
> ###################################################################
> 
> OrigData=read.csv("~/Dropbox/Post-Doc/OriginalDataFiles/GLBA_noDots.csv",
+                   header=TRUE)
> year=OrigData$year
> 
> ###
> ### 1999
> ###
> 
> d.99.tmp=subset(OrigData,year==1999)
> 
> ###
> ### Unique transects flown in 1999
> ###
> 
> ID=cumsum(!duplicated(d.99.tmp[,20:23]))
> d.99=cbind(d.99.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.99=list()
> Sl.99=list()
> S.99=list()
> ## 324, 342
> for(i in unique(ID)){
+     t.sub=subset(d.99,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.99[[i]]=coords
+     Sl.99[[i]]=Line(l.99[[i]])
+     S.99[[i]]=Lines(list(Sl.99[[i]]), ID=i)
+     Sb.99=SpatialLines(S.99)
+     ## plot(Sb.99)
+     ## readline()
+ 
+ }
> ## plot(Sb.99)
> 
> 
> ###
> ### 2000
> ###
> 
> d.00.tmp=subset(OrigData,year==2000)
> 
> ###
> ### Unique transects flown in 2000
> ###
> 
> ID=cumsum(!duplicated(d.00.tmp[,20:23]))
> d.00=cbind(d.00.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.00=list()
> Sl.00=list()
> S.00=list()
> 
> for(i in unique(ID)){ #493
+     t.sub=subset(d.00,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.00[[i]]=coords
+     Sl.00[[i]]=Line(l.00[[i]])
+     S.00[[i]]=Lines(list(Sl.00[[i]]), ID=i)
+     Sb.00=SpatialLines(S.00)
+     ## plot(Sb.00)
+     ## readline()
+ 
+ }
> 
> ## plot(Sb.00)
> 
> ###
> ### 2001
> ###
> 
> d.01.tmp=subset(OrigData,year==2001)
> 
> ###
> ### Unique transects flown in 2001
> ###
> 
> ID=cumsum(!duplicated(d.01.tmp[,20:23]))
> d.01=cbind(d.01.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.01=list()
> Sl.01=list()
> S.01=list()
> 
> for(i in unique(ID)[1:343]){  ## 343
+     t.sub=subset(d.01,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.01[[i]]=coords
+     Sl.01[[i]]=Line(l.01[[i]])
+     S.01[[i]]=Lines(list(Sl.01[[i]]), ID=i)
+     Sb.01=SpatialLines(S.01)
+     ## plot(Sb.01)
+     ## readline()
+ 
+ }
> ## plot(Sb.01)
> 
> ###
> ### 2002
> ###
> 
> d.02.tmp=subset(OrigData,year==2002)
> 
> ###
> ### Unique transects flown in 2002
> ###
> 
> ID=cumsum(!duplicated(d.02.tmp[,20:23]))
> d.02=cbind(d.02.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.02=list()
> Sl.02=list()
> S.02=list()
> 
> for(i in unique(ID)){  ## 514
+     t.sub=subset(d.02,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.02[[i]]=coords
+     Sl.02[[i]]=Line(l.02[[i]])
+     S.02[[i]]=Lines(list(Sl.02[[i]]), ID=i)
+     Sb.02=SpatialLines(S.02)
+     ## plot(Sb.02)
+     ## readline()
+ 
+ }
> ## plot(Sb.02)
> 
> ###
> ### 2003
> ###
> 
> d.03.tmp=subset(OrigData,year==2003)
> 
> ###
> ### Unique transects flown in 2003
> ###
> 
> ID=cumsum(!duplicated(d.03.tmp[,20:23]))
> d.03=cbind(d.03.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.03=list()
> Sl.03=list()
> S.03=list()
> 
> for(i in unique(ID)){  ## 514
+     t.sub=subset(d.03,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.03[[i]]=coords
+     Sl.03[[i]]=Line(l.03[[i]])
+     S.03[[i]]=Lines(list(Sl.03[[i]]), ID=i)
+     Sb.03=SpatialLines(S.03)
+     ## plot(Sb.03)
+     ## readline()
+ 
+ }
> ## plot(Sb.03)
> 
> ###
> ### 2004
> ###
> 
> d.04.tmp=subset(OrigData,year==2004)
> 
> ###
> ### Unique transects flown in 2004
> ###
> 
> ID=cumsum(!duplicated(d.04.tmp[,20:23]))
> d.04=cbind(d.04.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.04=list()
> Sl.04=list()
> S.04=list()
> 
> for(i in unique(ID)){  ## 417
+     t.sub=subset(d.04,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.04[[i]]=coords
+     Sl.04[[i]]=Line(l.04[[i]])
+     S.04[[i]]=Lines(list(Sl.04[[i]]), ID=i)
+     Sb.04=SpatialLines(S.04)
+ 
+ }
> ## plot(Sb.04)
> 
> ###
> ### 2006
> ###
> 
> d.06.tmp=subset(OrigData,year==2006)
> 
> ###
> ### Unique transects flown in 2006
> ###
> 
> ID=cumsum(!duplicated(d.06.tmp[,20:23]))
> d.06=cbind(d.06.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.06=list()
> Sl.06=list()
> S.06=list()
> 
> for(i in unique(ID)){  ## 365
+     t.sub=subset(d.06,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.06[[i]]=coords
+     Sl.06[[i]]=Line(l.06[[i]])
+     S.06[[i]]=Lines(list(Sl.06[[i]]), ID=i)
+     Sb.06=SpatialLines(S.06)
+ 
+ }
> ## plot(Sb.06)
> 
> ###
> ### 2012
> ###
> 
> d.12.tmp=subset(OrigData,year==2012)
> 
> ###
> ### Unique transects flown in 2012
> ###
> 
> ID=cumsum(!duplicated(d.12.tmp[,20:23]))
> d.12=cbind(d.12.tmp,ID)
> 
> ###
> ### Subset observation data for each transect
> ###
> 
> l.12=list()
> Sl.12=list()
> S.12=list()
> 
> for(i in unique(ID)[1:324]){  ## 347
+     t.sub=subset(d.12,ID==i)
+ 
+     ##
+     ## Store start, end, group location coordinates
+     ##
+ 
+     coords.tmp1=matrix(,dim(t.sub)*3,2)
+     colnames(coords.tmp1)=c("x","y")
+ 
+     ## West end point
+     coords.tmp1[1:dim(t.sub)[1],1]=t.sub$west_long
+     coords.tmp1[1:dim(t.sub)[1],2]=t.sub$west_lat
+ 
+     ## Group locations
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),1]=t.sub$GROUP_X
+     coords.tmp1[(dim(t.sub)[1]+1):(2*dim(t.sub)[1]),2]=t.sub$GROUP_Y
+ 
+     ## East end point
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),1]=t.sub$east_long
+     coords.tmp1[(2*dim(t.sub)[1]+1):(3*dim(t.sub)[1]),2]=t.sub$east_lat
+ 
+     ## Remove duplicates
+     coords.tmp2=unique(coords.tmp1)
+ 
+     ## Remove NA rows
+     coords.tmp3=coords.tmp2[!is.na(coords.tmp2[,1]),]
+ 
+     ## Order from left to right
+     coords=coords.tmp3[order(coords.tmp3[,1]),]
+ 
+     l.12[[i]]=coords
+     Sl.12[[i]]=Line(l.12[[i]])
+     S.12[[i]]=Lines(list(Sl.12[[i]]), ID=i)
+     Sb.12=SpatialLines(S.12)
+ 
+ }
> ## plot(Sb.12)
> 
> ##################################################
> ### Rasterize transects
> ##################################################
> 
> transectAll=raster(,nrows=y,ncols=x,xmn=xmin,
+                   xmx=xmax,ymn=ymin,ymx=ymax,crs=NA)
> transectAll[]=rep(NA,q)
> transectAll=stack(mget(rep("transectAll",20)))
> transectAll[[1]][]=rep(NA,q)
> transectAll[[2]][]=rep(NA,q)
> transectAll[[3]][]=rep(NA,q)
> transectAll[[4]][]=rep(NA,q)
> transectAll[[5]][]=rep(NA,q)
> transectAll[[6]][]=rep(NA,q)
> transectAll[[7]]=rasterize(x=Sb.99,y=transectAll[[7]],
+                          field=1,fun="last",background=NA)
> transectAll[[8]]=rasterize(x=Sb.00,y=transectAll[[8]],
+                          field=1,fun="last",background=NA)
> transectAll[[9]]=rasterize(x=Sb.01,y=transectAll[[9]],
+                          field=1,fun="last",background=NA)
> transectAll[[10]]=rasterize(x=Sb.02,y=transectAll[[10]],
+                          field=1,fun="last",background=NA)
> transectAll[[11]]=rasterize(x=Sb.03,y=transectAll[[11]],
+                          field=1,fun="last",background=NA)
> transectAll[[12]]=rasterize(x=Sb.04,y=transectAll[[12]],
+                          field=1,fun="last",background=NA)
> transectAll[[13]][]=rep(NA,q)
> transectAll[[14]]=rasterize(x=Sb.06,y=transectAll[[14]],
+                          field=1,fun="last",background=NA)
> transectAll[[15]][]=rep(NA,q)
> transectAll[[16]][]=rep(NA,q)
> transectAll[[17]][]=rep(NA,q)
> transectAll[[18]][]=rep(NA,q)
> transectAll[[19]][]=rep(NA,q)
> transectAll[[20]]=rasterize(x=Sb.12,y=transectAll[[20]],
+                          field=1,fun="last",background=NA)
> 
> ## plot(transectAll)
> 
> #####################################################
> ### Combine transect data and count data
> #####################################################
> 
> Y.r[]=Counts[[7]][]*transectAll[[7]][]
> Y.r=stack(mget(rep("Y.r",20)))
> for (i in 1:20) {
+   Y.r[[i]][]=ifelse(Counts[[i]][]>0,Counts[[i]][],
+     transectAll[[i]][]-1)
+ }
> ## plot(Y.r[[7]])
> 
> ######################################################
> ### Load ISU data
> ######################################################
> 
> all.ISU.data=read.csv(paste("~/Dropbox/Post-Doc/",
+                         "OriginalDataFiles/",
+                         "All ISUs 1999_2012_02032016.csv",
+                         sep=""))
> ISU.N=all.ISU.data$circle.adt+
+     all.ISU.data$circle.pup
> ISU.Y=all.ISU.data$strip.adt+
+     all.ISU.data$strip.pup
> ISU.N[ISU.Y>ISU.N]=ISU.Y[ISU.Y>ISU.N]
> sum(ISU.N<ISU.Y)
[1] 0
> ISU.year=all.ISU.data$year
> ISU.data=data.frame(ISU.N,ISU.Y,ISU.year)
> Y.1999=ISU.data$ISU.Y[ISU.data$ISU.year==1999]
> N.1999=ISU.data$ISU.N[ISU.data$ISU.year==1999]
> Y.2000=ISU.data$ISU.Y[ISU.data$ISU.year==2000]
> N.2000=ISU.data$ISU.N[ISU.data$ISU.year==2000]
> Y.2001=ISU.data$ISU.Y[ISU.data$ISU.year==2001]
> N.2001=ISU.data$ISU.N[ISU.data$ISU.year==2001]
> Y.2002=ISU.data$ISU.Y[ISU.data$ISU.year==2002]
> N.2002=ISU.data$ISU.N[ISU.data$ISU.year==2002]
> Y.2003=ISU.data$ISU.Y[ISU.data$ISU.year==2003]
> N.2003=ISU.data$ISU.N[ISU.data$ISU.year==2003]
> Y.2004=ISU.data$ISU.Y[ISU.data$ISU.year==2004]
> N.2004=ISU.data$ISU.N[ISU.data$ISU.year==2004]
> Y.2006=ISU.data$ISU.Y[ISU.data$ISU.year==2006]
> N.2006=ISU.data$ISU.N[ISU.data$ISU.year==2006]
> Y.2012=ISU.data$ISU.Y[ISU.data$ISU.year==2012]
> N.2012=ISU.data$ISU.N[ISU.data$ISU.year==2012]
> ISU=list(Y.1999=Y.1999,
+          N.1999=N.1999,
+          Y.2000=Y.2000,
+          N.2000=N.2000,
+          Y.2001=Y.2001,
+          N.2001=N.2001,
+          Y.2002=Y.2002,
+          N.2002=N.2002,
+          Y.2003=Y.2003,
+          N.2003=N.2003,
+          Y.2004=Y.2004,
+          N.2004=N.2004,
+          Y.2006=Y.2006,
+          N.2006=N.2006,
+          Y.2012=Y.2012,
+          N.2012=N.2012)
> 
> ###
> ### Create `Cell' raster
> ###
> 
> cell[]=1:q
> ## plot(cell)
> 
> ###
> ### Create Bounday raster
> ###
> 
> Boundary[is.na(bath)]=0
> Boundary[bath<0]=1
> Boundary[bath>=0]=0
> ## plot(Boundary)
> 
> BoundaryNA=Boundary
> BoundaryNA[Boundary==0]=NA
> ## plot(BoundaryNA)
> 
> BoundaryInf=BoundaryNA
> BoundaryInf[120:170,0:80]=NA
> BoundaryInf[150:170,0:140]=NA
> BoundaryInf[134:170,116:140]=NA
> BoundaryInf.v=rep(BoundaryInf[],length(keep))
> ## plot(BoundaryInf)
> 
> ###
> ### Up-scaled boundary layer surrounded by zeros
> ###
> 
> Boundary.us=aggregate(Boundary,fact=us.fact,na.rm=TRUE,fun=max)
> Boundary.us[Boundary.us[]>1]=1
> ## plot(Boundary.us)
> Boundary.us[1,]=0
> Boundary.us[,1]=0
> Boundary.us[dim(Boundary.us)[1],]=0
> Boundary.us[,dim(Boundary.us)[2]]=0
> ## plot(Boundary.us)
> 
> ###
> ### Depth covariate
> ###
> 
> depth=40
> DepthCov=bath
> DepthCov[bath[]< -depth]=0
> DepthCov[bath[]>= -depth]=1
> DepthCov[is.na(bath[])]=0
> DepthCov=DepthCov*Boundary
> ## plot(DepthCov)
> 
> ###
> ### Distance to shore covariate
> ###
> 
> DistCov.tmp1=Boundary
> DistCov.tmp1[Boundary==1]=NA
> DistCov.tmp2=distance(DistCov.tmp1)
> DistCov.tmp2[is.na(DistCov.tmp2)]=0
> DistCov=scale(DistCov.tmp2,center=TRUE,scale=TRUE)
> DistCov=DistCov*Boundary
> ## plot(DistCov)
> 
> ###
> ### Bottom slope
> ###
> 
> SlopeCov.tmp=terrain(bath,opt='slope',unit='degrees',neighbors=8)
> SlopeCov.tmp[is.na(SlopeCov.tmp)]=0
> SlopeCov=scale(SlopeCov.tmp, center=TRUE, scale=TRUE)
> SlopeCov=SlopeCov*Boundary*DepthCov
> ## plot(SlopeCov)
> 
> ###
> ### Shoreline complexity
> ###
> 
> ShoreCov.tmp=boundaries(DistCov.tmp1,type='inner')
> ShoreCov.tmp[is.na(ShoreCov.tmp)]=0
> ShoreCov=focal(ShoreCov.tmp,w=matrix(1,nr=11,nc=11))*Boundary
> ShoreCov[is.na(ShoreCov)]=0
> ShoreCov=scale(ShoreCov,center=TRUE, scale=TRUE)
> ShoreCov=ShoreCov*Boundary
> ## plot(ShoreCov)
> ## points(loc.data.UTM$lon,loc.data.UTM$lat,cex=0.2,pch=16)
> 
> ###
> ### Create co-variate matrices
> ###
> 
> X=cbind(1,DepthCov[],DistCov[],SlopeCov[]*DepthCov[],ShoreCov[])
> ## cor(X, use="pairwise.complete.obs")
> W=matrix(1,nr=q,nc=1)
> 
> 
> ###
> ### Data for analysis
> ###
> 
> Y=c(Y.r[[1]][],
+     Y.r[[2]][],
+     Y.r[[3]][],
+     Y.r[[4]][],
+     Y.r[[5]][],
+     Y.r[[6]][],
+     Y.r[[7]][],
+     Y.r[[8]][],
+     Y.r[[9]][],
+     Y.r[[10]][],
+     Y.r[[11]][],
+     Y.r[[12]][],
+     Y.r[[13]][],
+     Y.r[[14]][],
+     Y.r[[15]][],
+     Y.r[[16]][],
+     Y.r[[17]][],
+     Y.r[[18]][],
+     Y.r[[19]][],
+     Y.r[[20]][])
> 
> #################################################
> #################################################
> ###
> ### Fit the model to the real data using MCMC
> ###
> #################################################
> #################################################
> 
> 
> ###
> ### Bundle data
> ###
> 
> data=list(Y=Y,
+           ISU=ISU,
+           X=X)
> 
> ###
> ### Spatio-temporal settings
> ###
> 
> dt=1/200
> time.frame=1993:2012
> us.fact=10
> res=400
> d=c(442000,6465000)
> xmin=404000
> xmax=460000
> ymin=6460000
> ymax=6528000
> extent=c(xmin,xmax,ymin,ymax)
> st.info=list(dt=dt,
+              time.frame=time.frame,
+              us.fact=us.fact,
+              res=res,
+              d=d,
+              extent=extent
+              )
> 
> ###
> ### MCMC Settings
> ###
> 
> n.iter=50000
> checkpoint=10
> 
> ###
> ### Priors
> ###
> 
> ## beta
> mu.beta=0
> var.beta=10^2
> 
> ## gamma
> q.gamma=-0.5
> r.gamma=0.5
> 
> ## theta
> mu.theta=500
> var.theta=500
> 
> ## kappa
> mu.kappa=5.95
> var.kappa=5
> 
> ## p
> q.p=1
> r.p=1
> 
> ## tau
> q.tau=0
> r.tau=1
> 
> priors=list(
+     beta.prior=c(mu.beta,var.beta),
+     gamma.prior=c(q.gamma,r.gamma),
+     theta.prior=c(mu.theta,var.theta),
+     kappa.prior=c(mu.kappa,var.kappa),
+     p.prior=c(q.p,r.p),
+     tau.prior=c(q.tau,r.tau)
+ )
> 
> ###
> ### Starting values
> ###
> 
> gamma=0.20
> beta=c(17.72,-1.48,0.77,-0.35,1.0)
> theta=500
> kappa=5.95
> p.1999=0.80
> p.2000=0.75
> p.2001=0.86
> p.2002=0.85
> p.2003=0.76
> p.2004=0.77
> p.2006=0.75
> p.2012=0.58
> p=c(rep(NA,6*q),
+     rep(p.1999,q),
+     rep(p.2000,q),
+     rep(p.2001,q),
+     rep(p.2002,q),
+     rep(p.2003,q),
+     rep(p.2004,q),
+     rep(NA,q),
+     rep(p.2006,q),
+     rep(NA,q*5),
+     rep(p.2012,q))
> odp=0.5
> 
> inits=list(gamma=gamma,
+            beta=beta,
+            theta=theta,
+            kappa=kappa,
+            odp=odp,
+            p=p
+            )
> 
> ###
> ### Parameters to monitor
> ###
> 
> parameters=c("gamma",
+              "beta",
+              "kappa",
+              "theta",
+              "odp",
+              "p",
+              "n.tot")
> 
> ###
> ### Output location
> ###
> 
> output.location="~/GB_Output.RData"
> 
> Bathymetry=bath
> rm(list=ls()[!ls() %in% c("data",
+                           "priors",
+                           "inits",
+                           "parameters",
+                           "st.info",
+                           "Bathymetry",
+                           "n.iter",
+                           "checkpoint",
+                           "output.location")])
> 
> ###
> ### Run MCMC
> ###
> 
> script=getURL(
+     paste("https://raw.githubusercontent.com/perrywilliams/",
+           "GlacierBay-SeaOtter-Analysis/master/MCMC.R",sep=""),
+     ssl.verifypeer=FALSE)
> eval(parse(text = script))
> 
> ## source(paste("~/Dropbox/GitHub/GlacierBay-SeaOtter-Analysis/",
> ##              "GlacierBay-SeaOtter-Analysis/MCMC.R",sep=""))
> 
> MCMC(data,
+      priors,
+      inits,
+      parameters,
+      st.info,
+      Bathymetry,
+      n.iter=n.iter,
+      checkpoint=checkpoint,
+      output.location)
10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710 720 730 740 750 760 770 780 790 800 810 820 830 840 850 860 870 880 890 900 910 920 930 940 950 960 970 980 990 1000 1010 1020 1030 1040 1050 1060 1070 1080 1090 1100 1110 1120 1130 1140 1150 1160 1170 1180 1190 1200 1210 1220 1230 1240 1250 1260 1270 1280 1290 1300 1310 1320 1330 1340 1350 1360 1370 1380 1390 1400 1410 1420 1430 1440 1450 1460 1470 1480 1490 1500 1510 1520 1530 1540 1550 1560 1570 1580 1590 1600 1610 1620 1630 1640 1650 1660 1670 1680 1690 1700 1710 1720 1730 1740 1750 1760 1770 1780 1790 1800 1810 1820 1830 1840 1850 1860 1870 1880 1890 1900 1910 1920 1930 1940 1950 1960 1970 1980 1990 2000 2010 2020 2030 2040 2050 2060 2070 2080 2090 2100 2110 2120 2130 2140 2150 2160 2170 2180 2190 2200 2210 2220 2230 2240 2250 2260 2270 2280 2290 2300 2310 2320 2330 2340 2350 2360 2370 2380 2390 2400 2410 2420 2430 2440 2450 2460 2470 2480 2490 2500 2510 2520 2530 2540 2550 2560 2570 2580 2590 2600 2610 2620 2630 2640 2650 2660 2670 2680 2690 2700 2710 2720 2730 2740 2750 2760 2770 2780 2790 2800 2810 2820 2830 2840 2850 2860 2870 2880 2890 2900 2910 2920 2930 2940 2950 2960 2970 2980 2990 3000 3010 3020 3030 3040 3050 3060 3070 3080 3090 3100 3110 3120 3130 3140 3150 3160 3170 3180 3190 3200 3210 3220 3230 3240 3250 3260 3270 3280 3290 3300 3310 3320 3330 3340 3350 3360 3370 3380 3390 3400 3410 3420 3430 3440 3450 3460 3470 3480 3490 3500 3510 3520 3530 3540 3550 3560 3570 3580 3590 3600 3610 3620 3630 3640 3650 3660 3670 3680 3690 3700 3710 3720 3730 3740 3750 3760 3770 3780 3790 3800 3810 3820 3830 3840 3850 3860 3870 3880 3890 3900 3910 3920 3930 3940 3950 3960 3970 3980 3990 4000 4010 4020 4030 4040 4050 4060 4070 4080 4090 4100 4110 4120 4130 4140 4150 4160 4170 4180 4190 4200 4210 4220 4230 4240 4250 4260 4270 4280 4290 4300 4310 4320 4330 4340 4350 4360 4370 4380 4390 4400 4410 4420 4430 4440 4450 4460 4470 4480 4490 4500 4510 4520 4530 4540 4550 4560 4570 4580 4590 4600 4610 4620 4630 4640 4650 4660 4670 4680 4690 4700 4710 4720 4730 4740 4750 4760 4770 4780 4790 4800 4810 4820 4830 4840 4850 4860 4870 4880 4890 4900 4910 4920 4930 4940 4950 4960 4970 4980 4990 5000 5010 5020 5030 5040 5050 5060 5070 5080 5090 5100 5110 5120 5130 5140 5150 5160 5170 5180 5190 5200 5210 5220 5230 5240 5250 5260 5270 5280 5290 5300 5310 5320 5330 5340 5350 5360 5370 5380 5390 5400 5410 5420 5430 5440 5450 5460 5470 5480 5490 5500 5510 5520 5530 5540 5550 5560 5570 5580 5590 5600 5610 5620 5630 5640 5650 5660 5670 5680 5690 5700 5710 5720 5730 5740 5750 5760 5770 5780 5790 5800 5810 5820 5830 5840 5850 5860 5870 5880 5890 5900 5910 5920 5930 5940 5950 5960 5970 5980 5990 6000 6010 6020 6030 6040 6050 6060 6070 6080 6090 6100 6110 6120 6130 6140 6150 6160 6170 6180 6190 6200 6210 6220 6230 6240 6250 6260 6270 6280 6290 6300 6310 